#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é«˜çº§çˆ¬è™«è¿è¡Œè„šæœ¬
æä¾›ç®€å•çš„å‘½ä»¤è¡Œæ¥å£æ¥è¿è¡Œå¤šé¢†åŸŸçˆ¬è™«
"""

import argparse
import asyncio
import sys
import os
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from advanced_crawler import AsyncOpenAlexCrawler, ProgressManager, DatabaseManager

def print_banner():
    """æ‰“å°å¯åŠ¨æ¨ªå¹…"""
    print("="*70)
    print("ğŸš€ é«˜çº§å¤šé¢†åŸŸ OpenAlex çˆ¬è™«")
    print("="*70)
    print("åŠŸèƒ½ç‰¹ç‚¹:")
    print("â€¢ å¤šé¢†åŸŸè¦†ç›–ï¼šAIã€è®¡ç®—æœºã€ç”µå­ä¿¡æ¯ã€æ–‡å­¦ã€æ•™è‚²ç­‰14ä¸ªé¢†åŸŸ")
    print("â€¢ å¼‚æ­¥çˆ¬å–ï¼šé«˜æ•ˆå¹¶å‘å¤„ç†")
    print("â€¢ è¿›åº¦ä¿å­˜ï¼šæ”¯æŒæ–­ç‚¹ç»­ä¼ ")
    print("â€¢ å¤§å°æ§åˆ¶ï¼šè‡ªåŠ¨æ§åˆ¶æ•°æ®åº“åœ¨50GBä»¥ä¸‹")
    print("â€¢ æ™ºèƒ½è°ƒåº¦ï¼šä¼˜å…ˆçˆ¬å–AI/è®¡ç®—æœºé¢†åŸŸ")
    print("="*70)

def print_status(db_path: str):
    """æ‰“å°å½“å‰çŠ¶æ€"""
    if not os.path.exists(db_path):
        print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {db_path}")
        return
    
    # æ•°æ®åº“ä¿¡æ¯
    db_manager = DatabaseManager(db_path)
    total_papers = db_manager.get_paper_count()
    db_size = db_manager.get_db_size_mb()
    
    print(f"\nğŸ“Š æ•°æ®åº“çŠ¶æ€:")
    print(f"   æ–‡ä»¶: {db_path}")
    print(f"   å¤§å°: {db_size:.1f} MB")
    print(f"   è®ºæ–‡æ•°: {total_papers:,}")
    
    # è¿›åº¦ä¿¡æ¯
    progress_manager = ProgressManager()
    if progress_manager.progress:
        completed_tasks = sum(1 for p in progress_manager.progress.values() if p.completed)
        total_tasks = len(progress_manager.progress)
        
        print(f"\nğŸ“ˆ çˆ¬å–è¿›åº¦:")
        print(f"   å·²å®Œæˆä»»åŠ¡: {completed_tasks}/{total_tasks}")
        print(f"   å®Œæˆç‡: {(completed_tasks/total_tasks)*100:.1f}%")
        
        print(f"\nğŸ·ï¸  å„é¢†åŸŸè¿›åº¦:")
        for domain in ["äººå·¥æ™ºèƒ½", "è®¡ç®—æœºç§‘å­¦", "ç”µå­ä¿¡æ¯", "æ–‡å­¦", "æ•™è‚²å­¦"]:
            domain_stats = progress_manager.get_domain_stats(domain)
            max_papers = 500000 if domain == "äººå·¥æ™ºèƒ½" else 400000 if domain == "è®¡ç®—æœºç§‘å­¦" else 300000 if domain == "ç”µå­ä¿¡æ¯" else 100000
            progress_pct = (domain_stats['total_papers'] / max_papers) * 100
            print(f"   {domain}: {domain_stats['total_papers']:,}/{max_papers:,} ({progress_pct:.1f}%)")

async def run_crawler(db_path: str, max_concurrent: int = 2):
    """è¿è¡Œçˆ¬è™«"""
    print(f"\nğŸš€ å¯åŠ¨çˆ¬è™«...")
    print(f"   æ•°æ®åº“: {db_path}")
    print(f"   å¹¶å‘æ•°: {max_concurrent}")
    print(f"   æŒ‰ Ctrl+C å¯å®‰å…¨åœæ­¢")
    
    try:
        async with AsyncOpenAlexCrawler(db_path, max_concurrent) as crawler:
            await crawler.run_crawler()
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ç”¨æˆ·åœæ­¢çˆ¬è™«")
    except Exception as e:
        print(f"\nâŒ çˆ¬è™«è¿è¡Œå‡ºé”™: {e}")
        raise

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="é«˜çº§å¤šé¢†åŸŸ OpenAlex çˆ¬è™«",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python run_advanced_crawler.py                    # ä½¿ç”¨é»˜è®¤è®¾ç½®è¿è¡Œ
  python run_advanced_crawler.py --db my_db.db     # æŒ‡å®šæ•°æ®åº“æ–‡ä»¶
  python run_advanced_crawler.py --status          # æŸ¥çœ‹å½“å‰çŠ¶æ€
  python run_advanced_crawler.py --concurrent 5    # è®¾ç½®å¹¶å‘æ•°ä¸º5
        """
    )
    
    parser.add_argument(
        "--db", 
        default="openalex_advanced.db",
        help="æ•°æ®åº“æ–‡ä»¶è·¯å¾„ (é»˜è®¤: openalex_advanced.db)"
    )
    
    parser.add_argument(
        "--concurrent", 
        type=int, 
        default=2,
        help="æœ€å¤§å¹¶å‘è¯·æ±‚æ•° (é»˜è®¤: 2)"
    )
    
    parser.add_argument(
        "--status", 
        action="store_true",
        help="æ˜¾ç¤ºå½“å‰çˆ¬å–çŠ¶æ€"
    )
    
    parser.add_argument(
        "--quiet", 
        action="store_true",
        help="é™é»˜æ¨¡å¼ï¼Œä¸æ˜¾ç¤ºæ¨ªå¹…"
    )
    
    args = parser.parse_args()
    
    if not args.quiet:
        print_banner()
    
    if args.status:
        print_status(args.db)
        return
    
    # æ£€æŸ¥ä¾èµ–
    try:
        import aiohttp
    except ImportError:
        print("âŒ ç¼ºå°‘ä¾èµ–åŒ… aiohttp")
        print("è¯·è¿è¡Œ: pip install aiohttp")
        sys.exit(1)
    
    # è¿è¡Œçˆ¬è™«
    try:
        asyncio.run(run_crawler(args.db, args.concurrent))
    except KeyboardInterrupt:
        print("\nğŸ‘‹ å†è§!")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¼‚å¸¸: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
